{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## homework 4.2: investigating lists and dictionaries using functions\n",
    "\n",
    "In this assignment I will ask you to pick five relatively short texts (poems, paragraphs, short essays, song lyrics, whatever interests you). The main thing is to make sure that each text is around 10 - 20 lines or sentences long. Below, I have selected five poems by Wallace Stevens. In each cell I have made a variable that contains each poem, and then I pass that poem through a function called `text_to_dict` that makes a dictionary for each poem. The dictionary contains the title of the poem, the full text as one string, and a list that contains each line of the poem. The function will also make lists of sentences instead of lines if you want to investigate a prose text (sentence by sentence) instead of a poem (line by line).\n",
    "\n",
    "There are two parts of this assignment. \n",
    "\n",
    "**Part 1**, which should be easy, is to replace the poems with texts of your own choice--and choose to split them by lines or sentences. \n",
    "\n",
    "**Part 2** is to write functions that and investigate your texts. If you want to focus on the functions first, you can go straight to Part 2 and use the poems I have chosen. You can then go back and enter your own texts--your functions should work no matter what text you've chosen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell toImport regular expressions\n",
    "#And to initialize the all texts list that will contain all of your dictionaries of text\n",
    "import re\n",
    "all_texts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** understanding the text_to_dict function**\n",
    "\n",
    "You don't have to completely understand this function to use it, but you do need to understand its parameters. It takes three parameters:\n",
    "* `title` is a string you need to write inside function's parameters\n",
    "* `text` is the variable that holds the entire text\n",
    "* `poem` True/False parameter --if it is true it will split your text by line (`\\n`) \n",
    " \tIf it is false it will split your text by sentence ('[.?!])\n",
    "\n",
    "If you look at the function you will see that it builds a dictionary with the following fields:\n",
    "* `title` is the title of the text\n",
    "* `text_as_string` is the full text as a string\n",
    "* `lines` is a list of lines or sentences\n",
    "\n",
    "It returns a dictionary with those fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_dict(title,text,poem):\n",
    "    dict_of_this_text = {}\n",
    "    dict_of_this_text['title'] = title\n",
    "    dict_of_this_text['text_as_string'] = text\n",
    "    if poem:\n",
    "        text_to_list = text.strip().split('\\n')\n",
    "    else:\n",
    "        text_to_list = re.split(r\"[.?!]\",text)\n",
    "    dict_of_this_text['lines'] = text_to_list\n",
    "    return dict_of_this_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please note: the regular expression I am using to split by sentences\n",
    "#is highly flawed, it is actually impossible to write regular expression \n",
    "#that splits 100% perfectly by sentence, but feel free to use this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "\n",
    "The next five cells are exactly the same. They define five different texts, and then they pass each text through the `text_to_dict` function. And then they add the resulting dictionary to the all_texts list. \n",
    "\n",
    "In the five cells below enter your five selected texts.\n",
    "\n",
    "**You should do no coding at any point** until the very last cell before part two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To change the text, just put a new text between the quotation mark\n",
    "text0 = '''\n",
    "Whether I shall turn out to be the hero of my own life, or whether that station will be held by anybody else, these pages must show. To begin my life with the beginning of my life, I record that I was born (as I have been informed and believe) on a Friday, at twelve o'clock at night. It was remarked that the clock began to strike, and I began to cry, simultaneously.\n",
    "\n",
    "In consideration of the day and hour of my birth, it was declared by the nurse, and by some sage women in the neighbourhood who had taken a lively interest in me several months before there was any possibility of our becoming personally acquainted, first, that I was destined to be unlucky in life; and secondly, that I was privileged to see ghosts and spirits; both these gifts inevitably attaching, as they believed, to all unlucky infants of either gender, born towards the small hours on a Friday night.\n",
    "\n",
    "I need say nothing here, on the first head, because nothing can show better than my history whether that prediction was verified or falsified by the result. On the second branch of the question, I will only remark, that unless I ran through that part of my inheritance while I was still a baby, I have not come into it yet. But I do not at all complain of having been kept out of this property; and if anybody else should be in the present enjoyment of it, he is heartily welcome to keep it.\n",
    "\n",
    "I was born with a caul, which was advertised for sale, in the newspapers, at the low price of fifteen guineas. Whether sea–going people were short of money about that time, or were short of faith and preferred cork jackets, I don't know; all I know is, that there was but one solitary bidding, and that was from an attorney connected with the bill–broking business, who offered two pounds in cash, and the balance in sherry, but declined to be guaranteed from drowning on any higher bargain. Consequently the advertisement was withdrawn at a dead loss—for as to sherry, my poor dear mother's own sherry was in the market then—and ten years afterwards, the caul was put up in a raffle down in our part of the country, to fifty members at half–a–crown a head, the winner to spend five shillings. I was present myself, and I remember to have felt quite uncomfortable and confused, at a part of myself being disposed of in that way. The caul was won, I recollect, by an old lady with a hand–basket, who, very reluctantly, produced from it the stipulated five shillings, all in halfpence, and twopence halfpenny short—as it took an immense time and a great waste of arithmetic, to endeavour without any effect to prove to her. It is a fact which will be long remembered as remarkable down there, that she was never drowned, but died triumphantly in bed, at ninety–two. I have understood that it was, to the last, her proudest boast, that she never had been on the water in her life, except upon a bridge; and that over her tea (to which she was extremely partial) she, to the last, expressed her indignation at the impiety of mariners and others, who had the presumption to go 'meandering' about the world. It was in vain to represent to her that some conveniences, tea perhaps included, resulted from this objectionable practice. She always returned, with greater emphasis and with an instinctive knowledge of the strength of her objection, 'Let us have no meandering.'\n",
    "'''\n",
    "#Remember: you need to type the title into the first parameter\n",
    "#If you want to split by line choose True for the third parameter\n",
    "#If you want to split by sentence, choose False\n",
    "transform_it = text_to_dict(\"David Copperfield\",text0,False)\n",
    "all_texts.append(transform_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = '''\n",
    "Where the mind is without fear and the head is held high\n",
    "Where knowledge is free\n",
    "Where the world has not been broken up into fragments\n",
    "By narrow domestic walls\n",
    "Where words come out from the depth of truth\n",
    "Where tireless striving stretches its arms towards perfection\n",
    "Where the clear stream of reason has not lost its way\n",
    "Into the dreary desert sand of dead habit\n",
    "Where the mind is led forward by thee\n",
    "Into ever-widening thought and action\n",
    "Into that heaven of freedom, my Father, let my country awake.\n",
    "'''\n",
    "transform_it = text_to_dict(\"Where the mind is without fear\",text1,True)\n",
    "all_texts.append(transform_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = '''\n",
    "In those early amorphous years when memory had only just begun, when life was full of Beginnings and no Ends, and Everything was Forever, Esthappen and Rahel thought of themselves together as Me, and separately, individually, as We or Us. As though they were a rare breed of Siamese twins, physically separate, but with joint identities. \n",
    "\n",
    "Now, these years later, Rahel has a memory of waking up one night giggling at Estha's funny dream. \n",
    "\n",
    "She has other memories too that she has no right to have. \n",
    "\n",
    "She remembers, for instance (though she hadn't been there), what the Orangedrink Lemondrink Man did to Estha in Abhilash Talkies. She remembers the taste of the tomato sandwiches--Estha's sandwiches, that Estha ate--on the Madras Mail to Madras. \n",
    "\n",
    "And these are only the small things. \n",
    "\n",
    "Anyway, now she thinks of Estha and Rahel as Them, because, separately, the two of them are no longer what They were or ever thought They'd be. \n",
    "\n",
    "Ever. \n",
    "\n",
    "Their lives have a size and a shape now. Estha has his and Rahel hers. \n",
    "\n",
    "Edges, Borders, Boundaries, Brinks and Limits have appeared like a team of trolls on their separate horizons. Short creatures with long shadows, patrolling the Blurry End. Gentle half-moons have gathered under their eyes and they are as old as Ammu was when she died. Thirty-one. \n",
    "\n",
    "'''\n",
    "transform_it = text_to_dict(\"The God of Small Things\",text2,False)\n",
    "all_texts.append(transform_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where the mind is without fear'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[1]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = '''\n",
    "Look, if you had one shot, or one opportunity\n",
    "To seize everything you ever wanted, in one moment\n",
    "Would you capture it, or just let it slip?\n",
    "\n",
    "Yo! His palms are sweaty, knees weak, arms are heavy\n",
    "There's vomit on his sweater already: Mom's spaghetti\n",
    "He's nervous, but on the surface he looks calm and ready\n",
    "To drop bombs, but he keeps on forgetting\n",
    "What he wrote down, the whole crowd goes so loud\n",
    "He opens his mouth, but the words won't come out\n",
    "He's choking, how? Everybody's joking now\n",
    "The clock's run out, time's up, over—blaow!\n",
    "Snap back to reality, ope there goes gravity, ope\n",
    "There goes Rabbit, he choked, he's so mad but he won't\n",
    "Give up that easy, no, he won't have it, he knows\n",
    "His whole back's to these ropes, it don't matter, he's dope\n",
    "He knows that but he's broke, he's so stagnant, he knows\n",
    "When he goes back to this mobile home, that's when it's\n",
    "Back to the lab again yo, this whole rhapsody\n",
    "Better go capture this moment and hope it don't pass him, and\n",
    "\n",
    "His soul's escaping through this hole that is gaping\n",
    "This world is mine for the taking, make me king\n",
    "As we move toward a New World Order\n",
    "A normal life is boring; but superstardom's\n",
    "Close to post-mortem, it only grows harder\n",
    "Homie grows hotter, he blows, it's all over\n",
    "These hoes is all on him, coast-to-coast shows\n",
    "He's known as the Globetrotter, lonely roads\n",
    "God only knows, he's grown farther from home, he's no father\n",
    "He goes home and barely knows his own daughter\n",
    "But hold your nose, 'cause here goes the cold water\n",
    "These hoes don't want him no mo', he's cold product\n",
    "They moved on to the next schmoe who flows\n",
    "He nose-dove and sold nada, and so the soap opera\n",
    "Is told, it unfolds, I suppose it's old, partner\n",
    "But the beat goes on: da-da-dom, da-dom, dah-dah, dah-dah\n",
    "\n",
    "No more games, I'ma change what you call rage\n",
    "Tear this motherfuckin' roof off like two dogs caged\n",
    "I was playin' in the beginning, the mood all changed\n",
    "I've been chewed up and spit out and booed off stage\n",
    "But I kept rhymin' and stepped right in the next cypher\n",
    "Best believe somebody's payin' the Pied Piper\n",
    "All the pain inside amplified by the\n",
    "Fact that I can't get by with my nine-to-\n",
    "Five and I can't provide the right type of life for my family\n",
    "'Cause man, these goddamn food stamps don't buy diapers\n",
    "And there's no movie, there's no Mekhi Phifer, this is my life\n",
    "And these times are so hard, and it's gettin' even harder\n",
    "Tryna feed and water my seed, plus teeter-totter\n",
    "Caught up between bein' a father and a prima donna\n",
    "Baby mama drama, screamin' on her, too much for me to wanna\n",
    "Stay in one spot, another day of monotony's\n",
    "Gotten me to the point I'm like a snail, I've got\n",
    "To formulate a plot or end up in jail or shot\n",
    "Success is my only motherfuckin' option—failure's not\n",
    "Mom, I love you, but this trailer's got\n",
    "To go; I cannot grow old in Salem's Lot\n",
    "So here I go, it's my shot: feet, fail me not\n",
    "This may be the only opportunity that I got\n",
    "\n",
    "You better lose yourself in the music\n",
    "The moment, you own it, you better never let it go\n",
    "You only get one shot, do not miss your chance to blow\n",
    "This opportunity comes once in a lifetime, yo\n",
    "You better lose yourself in the music\n",
    "The moment, you own it, you better never let it go\n",
    "You only get one shot, do not miss your chance to blow\n",
    "This opportunity comes once in a lifetime, yo\n",
    "You better…\n",
    "'''\n",
    "transform_it = text_to_dict(\"Lose Yourself\",text3,True)\n",
    "all_texts.append(transform_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = '''\n",
    "Two roads diverged in a yellow wood,\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\n",
    "\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim,\n",
    "Because it was grassy and wanted wear;\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\n",
    "\n",
    "And both that morning equally lay\n",
    "In leaves no step had trodden black.\n",
    "Oh, I kept the first for another day!\n",
    "Yet knowing how way leads on to way,\n",
    "I doubted if I should ever come back.\n",
    "\n",
    "I shall be telling this with a sigh\n",
    "Somewhere ages and ages hence:\n",
    "Two roads diverged in a wood, and I—\n",
    "I took the one less traveled by,\n",
    "And that has made all the difference.\n",
    "'''\n",
    "transform_it = text_to_dict(\"The Road Not Taken\",text4,True)\n",
    "all_texts.append(transform_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the two cells below to confirm that first, you only have five texts in the all_texts list, and next, look at the all_texts list to see the dictionary inside it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'David Copperfield',\n",
       "  'text_as_string': \"\\nWhether I shall turn out to be the hero of my own life, or whether that station will be held by anybody else, these pages must show. To begin my life with the beginning of my life, I record that I was born (as I have been informed and believe) on a Friday, at twelve o'clock at night. It was remarked that the clock began to strike, and I began to cry, simultaneously.\\n\\nIn consideration of the day and hour of my birth, it was declared by the nurse, and by some sage women in the neighbourhood who had taken a lively interest in me several months before there was any possibility of our becoming personally acquainted, first, that I was destined to be unlucky in life; and secondly, that I was privileged to see ghosts and spirits; both these gifts inevitably attaching, as they believed, to all unlucky infants of either gender, born towards the small hours on a Friday night.\\n\\nI need say nothing here, on the first head, because nothing can show better than my history whether that prediction was verified or falsified by the result. On the second branch of the question, I will only remark, that unless I ran through that part of my inheritance while I was still a baby, I have not come into it yet. But I do not at all complain of having been kept out of this property; and if anybody else should be in the present enjoyment of it, he is heartily welcome to keep it.\\n\\nI was born with a caul, which was advertised for sale, in the newspapers, at the low price of fifteen guineas. Whether sea–going people were short of money about that time, or were short of faith and preferred cork jackets, I don't know; all I know is, that there was but one solitary bidding, and that was from an attorney connected with the bill–broking business, who offered two pounds in cash, and the balance in sherry, but declined to be guaranteed from drowning on any higher bargain. Consequently the advertisement was withdrawn at a dead loss—for as to sherry, my poor dear mother's own sherry was in the market then—and ten years afterwards, the caul was put up in a raffle down in our part of the country, to fifty members at half–a–crown a head, the winner to spend five shillings. I was present myself, and I remember to have felt quite uncomfortable and confused, at a part of myself being disposed of in that way. The caul was won, I recollect, by an old lady with a hand–basket, who, very reluctantly, produced from it the stipulated five shillings, all in halfpence, and twopence halfpenny short—as it took an immense time and a great waste of arithmetic, to endeavour without any effect to prove to her. It is a fact which will be long remembered as remarkable down there, that she was never drowned, but died triumphantly in bed, at ninety–two. I have understood that it was, to the last, her proudest boast, that she never had been on the water in her life, except upon a bridge; and that over her tea (to which she was extremely partial) she, to the last, expressed her indignation at the impiety of mariners and others, who had the presumption to go 'meandering' about the world. It was in vain to represent to her that some conveniences, tea perhaps included, resulted from this objectionable practice. She always returned, with greater emphasis and with an instinctive knowledge of the strength of her objection, 'Let us have no meandering.'\\n\",\n",
       "  'lines': ['\\nWhether I shall turn out to be the hero of my own life, or whether that station will be held by anybody else, these pages must show',\n",
       "   \" To begin my life with the beginning of my life, I record that I was born (as I have been informed and believe) on a Friday, at twelve o'clock at night\",\n",
       "   ' It was remarked that the clock began to strike, and I began to cry, simultaneously',\n",
       "   '\\n\\nIn consideration of the day and hour of my birth, it was declared by the nurse, and by some sage women in the neighbourhood who had taken a lively interest in me several months before there was any possibility of our becoming personally acquainted, first, that I was destined to be unlucky in life; and secondly, that I was privileged to see ghosts and spirits; both these gifts inevitably attaching, as they believed, to all unlucky infants of either gender, born towards the small hours on a Friday night',\n",
       "   '\\n\\nI need say nothing here, on the first head, because nothing can show better than my history whether that prediction was verified or falsified by the result',\n",
       "   ' On the second branch of the question, I will only remark, that unless I ran through that part of my inheritance while I was still a baby, I have not come into it yet',\n",
       "   ' But I do not at all complain of having been kept out of this property; and if anybody else should be in the present enjoyment of it, he is heartily welcome to keep it',\n",
       "   '\\n\\nI was born with a caul, which was advertised for sale, in the newspapers, at the low price of fifteen guineas',\n",
       "   \" Whether sea–going people were short of money about that time, or were short of faith and preferred cork jackets, I don't know; all I know is, that there was but one solitary bidding, and that was from an attorney connected with the bill–broking business, who offered two pounds in cash, and the balance in sherry, but declined to be guaranteed from drowning on any higher bargain\",\n",
       "   \" Consequently the advertisement was withdrawn at a dead loss—for as to sherry, my poor dear mother's own sherry was in the market then—and ten years afterwards, the caul was put up in a raffle down in our part of the country, to fifty members at half–a–crown a head, the winner to spend five shillings\",\n",
       "   ' I was present myself, and I remember to have felt quite uncomfortable and confused, at a part of myself being disposed of in that way',\n",
       "   ' The caul was won, I recollect, by an old lady with a hand–basket, who, very reluctantly, produced from it the stipulated five shillings, all in halfpence, and twopence halfpenny short—as it took an immense time and a great waste of arithmetic, to endeavour without any effect to prove to her',\n",
       "   ' It is a fact which will be long remembered as remarkable down there, that she was never drowned, but died triumphantly in bed, at ninety–two',\n",
       "   \" I have understood that it was, to the last, her proudest boast, that she never had been on the water in her life, except upon a bridge; and that over her tea (to which she was extremely partial) she, to the last, expressed her indignation at the impiety of mariners and others, who had the presumption to go 'meandering' about the world\",\n",
       "   ' It was in vain to represent to her that some conveniences, tea perhaps included, resulted from this objectionable practice',\n",
       "   \" She always returned, with greater emphasis and with an instinctive knowledge of the strength of her objection, 'Let us have no meandering\",\n",
       "   \"'\\n\"]},\n",
       " {'title': 'Where the mind is without fear',\n",
       "  'text_as_string': '\\nWhere the mind is without fear and the head is held high\\nWhere knowledge is free\\nWhere the world has not been broken up into fragments\\nBy narrow domestic walls\\nWhere words come out from the depth of truth\\nWhere tireless striving stretches its arms towards perfection\\nWhere the clear stream of reason has not lost its way\\nInto the dreary desert sand of dead habit\\nWhere the mind is led forward by thee\\nInto ever-widening thought and action\\nInto that heaven of freedom, my Father, let my country awake.\\n',\n",
       "  'lines': ['Where the mind is without fear and the head is held high',\n",
       "   'Where knowledge is free',\n",
       "   'Where the world has not been broken up into fragments',\n",
       "   'By narrow domestic walls',\n",
       "   'Where words come out from the depth of truth',\n",
       "   'Where tireless striving stretches its arms towards perfection',\n",
       "   'Where the clear stream of reason has not lost its way',\n",
       "   'Into the dreary desert sand of dead habit',\n",
       "   'Where the mind is led forward by thee',\n",
       "   'Into ever-widening thought and action',\n",
       "   'Into that heaven of freedom, my Father, let my country awake.']},\n",
       " {'title': 'The God of Small Things',\n",
       "  'text_as_string': \"\\nIn those early amorphous years when memory had only just begun, when life was full of Beginnings and no Ends, and Everything was Forever, Esthappen and Rahel thought of themselves together as Me, and separately, individually, as We or Us. As though they were a rare breed of Siamese twins, physically separate, but with joint identities. \\n\\nNow, these years later, Rahel has a memory of waking up one night giggling at Estha's funny dream. \\n\\nShe has other memories too that she has no right to have. \\n\\nShe remembers, for instance (though she hadn't been there), what the Orangedrink Lemondrink Man did to Estha in Abhilash Talkies. She remembers the taste of the tomato sandwiches--Estha's sandwiches, that Estha ate--on the Madras Mail to Madras. \\n\\nAnd these are only the small things. \\n\\nAnyway, now she thinks of Estha and Rahel as Them, because, separately, the two of them are no longer what They were or ever thought They'd be. \\n\\nEver. \\n\\nTheir lives have a size and a shape now. Estha has his and Rahel hers. \\n\\nEdges, Borders, Boundaries, Brinks and Limits have appeared like a team of trolls on their separate horizons. Short creatures with long shadows, patrolling the Blurry End. Gentle half-moons have gathered under their eyes and they are as old as Ammu was when she died. Thirty-one. \\n\\n\",\n",
       "  'lines': ['\\nIn those early amorphous years when memory had only just begun, when life was full of Beginnings and no Ends, and Everything was Forever, Esthappen and Rahel thought of themselves together as Me, and separately, individually, as We or Us',\n",
       "   ' As though they were a rare breed of Siamese twins, physically separate, but with joint identities',\n",
       "   \" \\n\\nNow, these years later, Rahel has a memory of waking up one night giggling at Estha's funny dream\",\n",
       "   ' \\n\\nShe has other memories too that she has no right to have',\n",
       "   \" \\n\\nShe remembers, for instance (though she hadn't been there), what the Orangedrink Lemondrink Man did to Estha in Abhilash Talkies\",\n",
       "   \" She remembers the taste of the tomato sandwiches--Estha's sandwiches, that Estha ate--on the Madras Mail to Madras\",\n",
       "   ' \\n\\nAnd these are only the small things',\n",
       "   \" \\n\\nAnyway, now she thinks of Estha and Rahel as Them, because, separately, the two of them are no longer what They were or ever thought They'd be\",\n",
       "   ' \\n\\nEver',\n",
       "   ' \\n\\nTheir lives have a size and a shape now',\n",
       "   ' Estha has his and Rahel hers',\n",
       "   ' \\n\\nEdges, Borders, Boundaries, Brinks and Limits have appeared like a team of trolls on their separate horizons',\n",
       "   ' Short creatures with long shadows, patrolling the Blurry End',\n",
       "   ' Gentle half-moons have gathered under their eyes and they are as old as Ammu was when she died',\n",
       "   ' Thirty-one',\n",
       "   ' \\n\\n']},\n",
       " {'title': 'Lose Yourself',\n",
       "  'text_as_string': \"\\nLook, if you had one shot, or one opportunity\\nTo seize everything you ever wanted, in one moment\\nWould you capture it, or just let it slip?\\n\\nYo! His palms are sweaty, knees weak, arms are heavy\\nThere's vomit on his sweater already: Mom's spaghetti\\nHe's nervous, but on the surface he looks calm and ready\\nTo drop bombs, but he keeps on forgetting\\nWhat he wrote down, the whole crowd goes so loud\\nHe opens his mouth, but the words won't come out\\nHe's choking, how? Everybody's joking now\\nThe clock's run out, time's up, over—blaow!\\nSnap back to reality, ope there goes gravity, ope\\nThere goes Rabbit, he choked, he's so mad but he won't\\nGive up that easy, no, he won't have it, he knows\\nHis whole back's to these ropes, it don't matter, he's dope\\nHe knows that but he's broke, he's so stagnant, he knows\\nWhen he goes back to this mobile home, that's when it's\\nBack to the lab again yo, this whole rhapsody\\nBetter go capture this moment and hope it don't pass him, and\\n\\nHis soul's escaping through this hole that is gaping\\nThis world is mine for the taking, make me king\\nAs we move toward a New World Order\\nA normal life is boring; but superstardom's\\nClose to post-mortem, it only grows harder\\nHomie grows hotter, he blows, it's all over\\nThese hoes is all on him, coast-to-coast shows\\nHe's known as the Globetrotter, lonely roads\\nGod only knows, he's grown farther from home, he's no father\\nHe goes home and barely knows his own daughter\\nBut hold your nose, 'cause here goes the cold water\\nThese hoes don't want him no mo', he's cold product\\nThey moved on to the next schmoe who flows\\nHe nose-dove and sold nada, and so the soap opera\\nIs told, it unfolds, I suppose it's old, partner\\nBut the beat goes on: da-da-dom, da-dom, dah-dah, dah-dah\\n\\nNo more games, I'ma change what you call rage\\nTear this motherfuckin' roof off like two dogs caged\\nI was playin' in the beginning, the mood all changed\\nI've been chewed up and spit out and booed off stage\\nBut I kept rhymin' and stepped right in the next cypher\\nBest believe somebody's payin' the Pied Piper\\nAll the pain inside amplified by the\\nFact that I can't get by with my nine-to-\\nFive and I can't provide the right type of life for my family\\n'Cause man, these goddamn food stamps don't buy diapers\\nAnd there's no movie, there's no Mekhi Phifer, this is my life\\nAnd these times are so hard, and it's gettin' even harder\\nTryna feed and water my seed, plus teeter-totter\\nCaught up between bein' a father and a prima donna\\nBaby mama drama, screamin' on her, too much for me to wanna\\nStay in one spot, another day of monotony's\\nGotten me to the point I'm like a snail, I've got\\nTo formulate a plot or end up in jail or shot\\nSuccess is my only motherfuckin' option—failure's not\\nMom, I love you, but this trailer's got\\nTo go; I cannot grow old in Salem's Lot\\nSo here I go, it's my shot: feet, fail me not\\nThis may be the only opportunity that I got\\n\\nYou better lose yourself in the music\\nThe moment, you own it, you better never let it go\\nYou only get one shot, do not miss your chance to blow\\nThis opportunity comes once in a lifetime, yo\\nYou better lose yourself in the music\\nThe moment, you own it, you better never let it go\\nYou only get one shot, do not miss your chance to blow\\nThis opportunity comes once in a lifetime, yo\\nYou better…\\n\",\n",
       "  'lines': ['Look, if you had one shot, or one opportunity',\n",
       "   'To seize everything you ever wanted, in one moment',\n",
       "   'Would you capture it, or just let it slip?',\n",
       "   '',\n",
       "   'Yo! His palms are sweaty, knees weak, arms are heavy',\n",
       "   \"There's vomit on his sweater already: Mom's spaghetti\",\n",
       "   \"He's nervous, but on the surface he looks calm and ready\",\n",
       "   'To drop bombs, but he keeps on forgetting',\n",
       "   'What he wrote down, the whole crowd goes so loud',\n",
       "   \"He opens his mouth, but the words won't come out\",\n",
       "   \"He's choking, how? Everybody's joking now\",\n",
       "   \"The clock's run out, time's up, over—blaow!\",\n",
       "   'Snap back to reality, ope there goes gravity, ope',\n",
       "   \"There goes Rabbit, he choked, he's so mad but he won't\",\n",
       "   \"Give up that easy, no, he won't have it, he knows\",\n",
       "   \"His whole back's to these ropes, it don't matter, he's dope\",\n",
       "   \"He knows that but he's broke, he's so stagnant, he knows\",\n",
       "   \"When he goes back to this mobile home, that's when it's\",\n",
       "   'Back to the lab again yo, this whole rhapsody',\n",
       "   \"Better go capture this moment and hope it don't pass him, and\",\n",
       "   '',\n",
       "   \"His soul's escaping through this hole that is gaping\",\n",
       "   'This world is mine for the taking, make me king',\n",
       "   'As we move toward a New World Order',\n",
       "   \"A normal life is boring; but superstardom's\",\n",
       "   'Close to post-mortem, it only grows harder',\n",
       "   \"Homie grows hotter, he blows, it's all over\",\n",
       "   'These hoes is all on him, coast-to-coast shows',\n",
       "   \"He's known as the Globetrotter, lonely roads\",\n",
       "   \"God only knows, he's grown farther from home, he's no father\",\n",
       "   'He goes home and barely knows his own daughter',\n",
       "   \"But hold your nose, 'cause here goes the cold water\",\n",
       "   \"These hoes don't want him no mo', he's cold product\",\n",
       "   'They moved on to the next schmoe who flows',\n",
       "   'He nose-dove and sold nada, and so the soap opera',\n",
       "   \"Is told, it unfolds, I suppose it's old, partner\",\n",
       "   'But the beat goes on: da-da-dom, da-dom, dah-dah, dah-dah',\n",
       "   '',\n",
       "   \"No more games, I'ma change what you call rage\",\n",
       "   \"Tear this motherfuckin' roof off like two dogs caged\",\n",
       "   \"I was playin' in the beginning, the mood all changed\",\n",
       "   \"I've been chewed up and spit out and booed off stage\",\n",
       "   \"But I kept rhymin' and stepped right in the next cypher\",\n",
       "   \"Best believe somebody's payin' the Pied Piper\",\n",
       "   'All the pain inside amplified by the',\n",
       "   \"Fact that I can't get by with my nine-to-\",\n",
       "   \"Five and I can't provide the right type of life for my family\",\n",
       "   \"'Cause man, these goddamn food stamps don't buy diapers\",\n",
       "   \"And there's no movie, there's no Mekhi Phifer, this is my life\",\n",
       "   \"And these times are so hard, and it's gettin' even harder\",\n",
       "   'Tryna feed and water my seed, plus teeter-totter',\n",
       "   \"Caught up between bein' a father and a prima donna\",\n",
       "   \"Baby mama drama, screamin' on her, too much for me to wanna\",\n",
       "   \"Stay in one spot, another day of monotony's\",\n",
       "   \"Gotten me to the point I'm like a snail, I've got\",\n",
       "   'To formulate a plot or end up in jail or shot',\n",
       "   \"Success is my only motherfuckin' option—failure's not\",\n",
       "   \"Mom, I love you, but this trailer's got\",\n",
       "   \"To go; I cannot grow old in Salem's Lot\",\n",
       "   \"So here I go, it's my shot: feet, fail me not\",\n",
       "   'This may be the only opportunity that I got',\n",
       "   '',\n",
       "   'You better lose yourself in the music',\n",
       "   'The moment, you own it, you better never let it go',\n",
       "   'You only get one shot, do not miss your chance to blow',\n",
       "   'This opportunity comes once in a lifetime, yo',\n",
       "   'You better lose yourself in the music',\n",
       "   'The moment, you own it, you better never let it go',\n",
       "   'You only get one shot, do not miss your chance to blow',\n",
       "   'This opportunity comes once in a lifetime, yo',\n",
       "   'You better…']},\n",
       " {'title': 'The Road Not Taken',\n",
       "  'text_as_string': '\\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\n\\nAnd both that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I kept the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\\n',\n",
       "  'lines': ['Two roads diverged in a yellow wood,',\n",
       "   'And sorry I could not travel both',\n",
       "   'And be one traveler, long I stood',\n",
       "   'And looked down one as far as I could',\n",
       "   'To where it bent in the undergrowth;',\n",
       "   '',\n",
       "   'Then took the other, as just as fair,',\n",
       "   'And having perhaps the better claim,',\n",
       "   'Because it was grassy and wanted wear;',\n",
       "   'Though as for that the passing there',\n",
       "   'Had worn them really about the same,',\n",
       "   '',\n",
       "   'And both that morning equally lay',\n",
       "   'In leaves no step had trodden black.',\n",
       "   'Oh, I kept the first for another day!',\n",
       "   'Yet knowing how way leads on to way,',\n",
       "   'I doubted if I should ever come back.',\n",
       "   '',\n",
       "   'I shall be telling this with a sigh',\n",
       "   'Somewhere ages and ages hence:',\n",
       "   'Two roads diverged in a wood, and I—',\n",
       "   'I took the one less traveled by,',\n",
       "   'And that has made all the difference.']}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, loop through all_texts and print out the title of each text. (This is the only code you need to write for Part One.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Copperfield\n",
      "Where the mind is without fear\n",
      "The God of Small Things\n",
      "Lose Yourself\n",
      "The Road Not Taken\n",
      "dict_keys(['title', 'text_as_string', 'lines'])\n",
      "dict_keys(['title', 'text_as_string', 'lines'])\n",
      "dict_keys(['title', 'text_as_string', 'lines'])\n",
      "dict_keys(['title', 'text_as_string', 'lines'])\n",
      "dict_keys(['title', 'text_as_string', 'lines'])\n"
     ]
    }
   ],
   "source": [
    "for text in all_texts:\n",
    "    print(text[\"title\"])\n",
    "\n",
    "for text in all_texts:\n",
    "    print(text.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two:  searching within lists and dictionaries\n",
    "In this part, we will be searching through each text and printing out a desired result. The searches, including loops and printing should all be defined in the function. The second cell should just have to function call that executes the function. I have written an example function and call for the first search. For each function that you write you should copy the original function and modify it so what does what I ask for.\n",
    "\n",
    "For the first five functions, there are no parameters passed to the functions--the calls will just execute the function. Go step-by-step and take your time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lengths():\n",
    "    for text in all_texts:\n",
    "        print(text['title'])\n",
    "        print(len(text['text_as_string']))\n",
    "        print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Copperfield\n",
      "3339\n",
      "------------\n",
      "Where the mind is without fear\n",
      "502\n",
      "------------\n",
      "The God of Small Things\n",
      "1298\n",
      "------------\n",
      "Lose Yourself\n",
      "3284\n",
      "------------\n",
      "The Road Not Taken\n",
      "731\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "get_lengths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "Now write a function that gets the **line count for each poem** (or sentence count for each piece of prose). This function is going to be very similar to the last one. Instead of accessing the whole text via text['text_as_string'] which is a string, you need to access the list of lines/sentences and get the length of that list. Everything else should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your function here, name it get_line_count()\n",
    "def get_line_count():\n",
    "    for line in all_texts:\n",
    "        print(line[\"title\"])\n",
    "        print(len(line[\"lines\"]))\n",
    "        print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Copperfield\n",
      "17\n",
      "---------------\n",
      "Where the mind is without fear\n",
      "11\n",
      "---------------\n",
      "The God of Small Things\n",
      "16\n",
      "---------------\n",
      "Lose Yourself\n",
      "71\n",
      "---------------\n",
      "The Road Not Taken\n",
      "23\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "get_line_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2\n",
    "Now write a function that prints out **one random line or sentence from each text**. Again, this function will look much the same as the last ones, but instead of getting numbers you need to get actual lines. I have included the necessary import and an example of how to get random integers. Basically, for each text you need to get one element from the list of lines/ sentences with a random number between 0 and the length of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def show_random_lines():\n",
    "    for line in all_texts:\n",
    "        length=len(line[\"lines\"])\n",
    "        import random\n",
    "        n=random.randint(0,length)\n",
    "        print(line[\"title\"])\n",
    "        print(line[\"lines\"][n])\n",
    "        print(\"---------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Copperfield\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fce2cd1650cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshow_random_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-f9c024eb0c49>\u001b[0m in \u001b[0;36mshow_random_lines\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lines\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "show_random_lines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3\n",
    "This is a little bit different--instead of printing out something from each text, I want you to **print the entire text of the longest text**. Remember in the first function, I printed out the length of each text. Well, you need to test for the longest text as you look through and when you're done looping through print out the one that is longest.\n",
    "\n",
    "**Major hints!**: To do this you will need two **tracking variables** set before the loop runs: A numerical one that tracks the longest length (the number), and string variable remembers the actual text that has that length.\n",
    "\n",
    "Like this: longest_length = 0 and longest_text = \"\"\n",
    "\n",
    "When you loop through you need to test if each text was longer than the last one, and if it is longer--you update longest_length and longest_text to reflect the highest length, and the actual text. When the loop is over you then print out that longest_text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your function here, name it longest_text()\n",
    "def longest_text():\n",
    "    lengths=[len(text[\"lines\"]) for text in all_texts]\n",
    "    x=max(lengths)\n",
    "    for text in all_texts:\n",
    "        if len(text[\"lines\"])==x:\n",
    "            print(text[\"title\"])\n",
    "            print(text[\"text_as_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4\n",
    "This is kind of a combination of the first two functions--write a function that gets the **average line/sentence length for each text**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def average_line_length():\n",
    "    for texts in all_texts:\n",
    "        sentence_length=[len(words) for words in texts[\"lines\"]]\n",
    "        print(texts[\"title\"])\n",
    "        print(f\"The mean length of a sentence in this text is {statistics.mean(sentence_length):.2f} letters\")\n",
    "        print(\"---------------------------------------------------------------------------------\")\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_line_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5\n",
    "**Print the longest line/sentence in each text**. \n",
    "This is similar to question 3--but your two tracking variables (longest_length and longest_line) need to be placed right before the inside loop--and then you print the lines each time the inside loop ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_line_in_each():\n",
    "    for texts in all_texts:\n",
    "        sentence_length=[len(words) for words in texts[\"lines\"]]\n",
    "        longest_sentence_in_text=(max(sentence_length))\n",
    "        print(texts[\"title\"])\n",
    "        for words in texts[\"lines\"]:\n",
    "            if len(words)==longest_sentence_in_text:\n",
    "                print(words)\n",
    "                print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_line_in_each()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6\n",
    "**Print the shortest single line/sentence out of all of the texts that is greater than zero**\n",
    "This is the tricky-ish: You need to place the tracking variables outside the loop (like question 4, but the loop through all of the lines, test for the shortest one (greater than 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_of_all_lines():\n",
    "    for texts in all_texts:\n",
    "        sentence_length=[len(words) for words in texts[\"lines\"] if len(words)>0]\n",
    "        shortest_sentence_in_text=(min(sentence_length))\n",
    "        print(texts[\"title\"])\n",
    "        for words in texts[\"lines\"]:\n",
    "            if len(words)==shortest_sentence_in_text:\n",
    "                print(words)\n",
    "                print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_of_all_lines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## searching with regular expressions\n",
    "In the functions below you will search all the texts using regular expressions. The first few of these functions should not be too challenging--you just need to adjust the regular expression inside the function. At points it gets a little more complex as you have to control the looping through the lists and dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_this_word(word):\n",
    "    my_regex = r\"\\b\" + word + r\"\\b\"\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.search(my_regex, line, re.IGNORECASE)]\n",
    "        if len(result) > 0:\n",
    "            print(text['title'])\n",
    "            [print(line) for line in result]\n",
    "            print(\"------------\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_this_word('deal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7\n",
    "Print out the lines that **start** with the word entered.  You just need to adjust the regular expression here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_starts_with(word):\n",
    "    my_regex = r\"^\" + word + r\"\\b\"\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.search(my_regex, line, re.IGNORECASE)]\n",
    "        if len(result) > 0:\n",
    "            print(text['title'])\n",
    "            [print(line) for line in result]\n",
    "            print(\"------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_starts_with('The')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8\n",
    "Print out the lines that **end** with the word entered.  You just need to adjust the regular expression here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_ends_with(word):\n",
    "    my_regex = word + r\"\\b\" + r\"$\"\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.search(my_regex, line, re.IGNORECASE)]\n",
    "        if len(result) > 0:\n",
    "            print(text['title'])\n",
    "            [print(line) for line in result]\n",
    "            print(\"------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_ends_with('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9\n",
    "Print out **how many times the word was found in each text.** In this case, instead of the list comprehension, you want to run a re.findall() on the string of the text (not the list) and then count the number of elements in the list of results.\n",
    "\n",
    "Hint: use the original function at the beginning of this section, and make the proper adjustments to the variable \"result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_times(word):\n",
    "    my_regex = r\"\\b\" + word + r\"\\b\"\n",
    "    print(my_regex)\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.findall(my_regex, line, re.IGNORECASE)]\n",
    "        if len(result) > 0:\n",
    "            print(text['title'])\n",
    "            print (len(result))\n",
    "            print(\"------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many_times('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10\n",
    "Print out **the text that has the highest occurrence of the word** you searched for. This is similar to the last function, but here you need tracking variables like you had in Question 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths=[]\n",
    "\n",
    "def text_with_most_occurance_of (word):\n",
    "    my_regex = r\"\\b\" + word + r\"\\b\"\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.findall(my_regex, line, re.IGNORECASE)]\n",
    "        lengths.append(len(result))  \n",
    "    most_occurance=max(lengths)\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.findall(my_regex, line, re.IGNORECASE)]\n",
    "        if len(result)==most_occurance:\n",
    "            print(text[\"title\"],\"has the most ccurances of the word.\")\n",
    "            print(len(result))\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_most_occurance_of('the')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 11\n",
    "Print out **lines containing words of the length asked**. We are sort of back to basics here, you just need to modify the regular expression of the first function (get_this_word(word)) so that it can take a number parameter for the length of characters in a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_with_words_this_length (length):\n",
    "    my_regex = r\"\\b\" + r\"\\w{\" +length + r\"}\\b\"\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.findall(my_regex, line, re.IGNORECASE)]\n",
    "        print(text[\"title\"])\n",
    "        print(len(result), \"lines in this text has a word with length\", length)\n",
    "        [print(line) for line in result]\n",
    "        print(\"------------------------\")\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_with_words_this_length('10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Final question:** in this cell, describe two functions that you would like to write, not ones that you're able to write, but ones you think would be useful or interesting or fun. If you feel like trying to write it, go-ahead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can't link these texts - they too diverse, so I have just written 2 random fuctions that don't seem of much use\n",
    "\n",
    "#Function to identify first person pronouns\n",
    "\n",
    "def pronoun():\n",
    "    my_regex = r\"\\b[i(me)(mine)(myself)(self)(we)(us)(ours(our))]\\b\"\n",
    "    print(my_regex)\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.findall(my_regex, line, re.IGNORECASE)]\n",
    "        if len(result) > 0:\n",
    "            print(text['title'])\n",
    "            print (len(result))\n",
    "            print(\"------------\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can't link these texts - they too diverse, so I have just written 2 random fuctions that don't seem of much use\n",
    "\n",
    "#Function to identify second/third person pronouns\n",
    "\n",
    "def first_person_pronoun():\n",
    "    my_regex = r\"\\b[I(Me)(Mine)(Myself)(self)]\\b\"\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.findall(my_regex, line, re.IGNORECASE)]\n",
    "        if len(result) > 0:\n",
    "            print(text['title'])\n",
    "            print (len(result))\n",
    "            print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person_pronoun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to identify second/third person pronouns\n",
    "\n",
    "def other_person_pronoun():\n",
    "    my_regex = r\"\\b[(you)(your)(yours)(they)(them)(their)(theirs)]\\b\"\n",
    "    for text in all_texts:\n",
    "        result = [line for line in text['lines'] if re.findall(my_regex, line, re.IGNORECASE)]\n",
    "        if len(result) > 0:\n",
    "            print(text['title'])\n",
    "            print (len(result))\n",
    "            print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_person_pronoun()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Bonus question:** Write a function that counts word frequency: that is, it returns a dictionary with each unique word and its count, sorted by the most frequent. Note, this is highly stack-overflowable -- Python has some built in ways of doing this. If you're doing this, you might as well try to do it on your own. But it's up to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whether': 4,\n",
       " 'i': 42,\n",
       " 'shall': 2,\n",
       " 'turn': 1,\n",
       " 'out': 6,\n",
       " 'to': 43,\n",
       " 'be': 10,\n",
       " 'the': 76,\n",
       " 'hero': 1,\n",
       " 'of': 35,\n",
       " 'my': 15,\n",
       " 'own': 5,\n",
       " 'life': 9,\n",
       " 'or': 9,\n",
       " 'that': 29,\n",
       " 'station': 1,\n",
       " 'will': 3,\n",
       " 'held': 2,\n",
       " 'by': 10,\n",
       " 'anybody': 2,\n",
       " 'else': 2,\n",
       " 'these': 9,\n",
       " 'pages': 1,\n",
       " 'must': 1,\n",
       " 'show': 2,\n",
       " 'begin': 1,\n",
       " 'with': 10,\n",
       " 'beginning': 2,\n",
       " 'record': 1,\n",
       " 'was': 26,\n",
       " 'born': 3,\n",
       " 'as': 18,\n",
       " 'have': 10,\n",
       " 'been': 6,\n",
       " 'informed': 1,\n",
       " 'and': 54,\n",
       " 'believe': 2,\n",
       " 'on': 16,\n",
       " 'a': 30,\n",
       " 'friday': 2,\n",
       " 'at': 10,\n",
       " 'twelve': 1,\n",
       " 'o': 1,\n",
       " 'clock': 3,\n",
       " 'night': 3,\n",
       " 'it': 28,\n",
       " 'remarked': 1,\n",
       " 'began': 2,\n",
       " 'strike': 1,\n",
       " 'cry': 1,\n",
       " 'simultaneously': 1,\n",
       " 'in': 32,\n",
       " 'consideration': 1,\n",
       " 'day': 3,\n",
       " 'hour': 1,\n",
       " 'birth': 1,\n",
       " 'declared': 1,\n",
       " 'nurse': 1,\n",
       " 'some': 2,\n",
       " 'sage': 1,\n",
       " 'women': 1,\n",
       " 'neighbourhood': 1,\n",
       " 'who': 5,\n",
       " 'had': 7,\n",
       " 'taken': 1,\n",
       " 'lively': 1,\n",
       " 'interest': 1,\n",
       " 'me': 6,\n",
       " 'several': 1,\n",
       " 'months': 1,\n",
       " 'before': 1,\n",
       " 'there': 10,\n",
       " 'any': 3,\n",
       " 'possibility': 1,\n",
       " 'our': 2,\n",
       " 'becoming': 1,\n",
       " 'personally': 1,\n",
       " 'acquainted': 1,\n",
       " 'first': 3,\n",
       " 'destined': 1,\n",
       " 'unlucky': 2,\n",
       " 'secondly': 1,\n",
       " 'privileged': 1,\n",
       " 'see': 1,\n",
       " 'ghosts': 1,\n",
       " 'spirits': 1,\n",
       " 'both': 3,\n",
       " 'gifts': 1,\n",
       " 'inevitably': 1,\n",
       " 'attaching': 1,\n",
       " 'they': 6,\n",
       " 'believed': 1,\n",
       " 'all': 9,\n",
       " 'infants': 1,\n",
       " 'either': 1,\n",
       " 'gender': 1,\n",
       " 'towards': 2,\n",
       " 'small': 2,\n",
       " 'hours': 1,\n",
       " 'need': 1,\n",
       " 'say': 1,\n",
       " 'nothing': 2,\n",
       " 'here': 3,\n",
       " 'head': 3,\n",
       " 'because': 3,\n",
       " 'can': 3,\n",
       " 'better': 8,\n",
       " 'than': 1,\n",
       " 'history': 1,\n",
       " 'prediction': 1,\n",
       " 'verified': 1,\n",
       " 'falsified': 1,\n",
       " 'result': 1,\n",
       " 'second': 1,\n",
       " 'branch': 1,\n",
       " 'question': 1,\n",
       " 'only': 9,\n",
       " 'remark': 1,\n",
       " 'unless': 1,\n",
       " 'ran': 1,\n",
       " 'through': 2,\n",
       " 'part': 3,\n",
       " 'inheritance': 1,\n",
       " 'while': 1,\n",
       " 'still': 1,\n",
       " 'baby': 2,\n",
       " 'not': 9,\n",
       " 'come': 4,\n",
       " 'into': 5,\n",
       " 'yet': 2,\n",
       " 'but': 15,\n",
       " 'do': 3,\n",
       " 'complain': 1,\n",
       " 'having': 2,\n",
       " 'kept': 3,\n",
       " 'this': 14,\n",
       " 'property': 1,\n",
       " 'if': 3,\n",
       " 'should': 2,\n",
       " 'present': 2,\n",
       " 'enjoyment': 1,\n",
       " 'he': 25,\n",
       " 'is': 14,\n",
       " 'heartily': 1,\n",
       " 'welcome': 1,\n",
       " 'keep': 1,\n",
       " 'caul': 3,\n",
       " 'which': 3,\n",
       " 'advertised': 1,\n",
       " 'for': 8,\n",
       " 'sale': 1,\n",
       " 'newspapers': 1,\n",
       " 'low': 1,\n",
       " 'price': 1,\n",
       " 'fifteen': 1,\n",
       " 'guineas': 1,\n",
       " 'sea': 1,\n",
       " 'going': 1,\n",
       " 'people': 1,\n",
       " 'were': 4,\n",
       " 'short': 4,\n",
       " 'money': 1,\n",
       " 'about': 3,\n",
       " 'time': 3,\n",
       " 'faith': 1,\n",
       " 'preferred': 1,\n",
       " 'cork': 1,\n",
       " 'jackets': 1,\n",
       " 'don': 5,\n",
       " 't': 11,\n",
       " 'know': 2,\n",
       " 'one': 12,\n",
       " 'solitary': 1,\n",
       " 'bidding': 1,\n",
       " 'from': 6,\n",
       " 'an': 4,\n",
       " 'attorney': 1,\n",
       " 'connected': 1,\n",
       " 'bill': 1,\n",
       " 'broking': 1,\n",
       " 'business': 1,\n",
       " 'offered': 1,\n",
       " 'two': 6,\n",
       " 'pounds': 1,\n",
       " 'cash': 1,\n",
       " 'balance': 1,\n",
       " 'sherry': 3,\n",
       " 'declined': 1,\n",
       " 'guaranteed': 1,\n",
       " 'drowning': 1,\n",
       " 'higher': 1,\n",
       " 'bargain': 1,\n",
       " 'consequently': 1,\n",
       " 'advertisement': 1,\n",
       " 'withdrawn': 1,\n",
       " 'dead': 2,\n",
       " 'loss': 1,\n",
       " 'poor': 1,\n",
       " 'dear': 1,\n",
       " 'mother': 1,\n",
       " 's': 34,\n",
       " 'market': 1,\n",
       " 'then': 2,\n",
       " 'ten': 1,\n",
       " 'years': 3,\n",
       " 'afterwards': 1,\n",
       " 'put': 1,\n",
       " 'up': 8,\n",
       " 'raffle': 1,\n",
       " 'down': 4,\n",
       " 'country': 2,\n",
       " 'fifty': 1,\n",
       " 'members': 1,\n",
       " 'half': 2,\n",
       " 'crown': 1,\n",
       " 'winner': 1,\n",
       " 'spend': 1,\n",
       " 'five': 3,\n",
       " 'shillings': 2,\n",
       " 'myself': 2,\n",
       " 'remember': 1,\n",
       " 'felt': 1,\n",
       " 'quite': 1,\n",
       " 'uncomfortable': 1,\n",
       " 'confused': 1,\n",
       " 'being': 1,\n",
       " 'disposed': 1,\n",
       " 'way': 4,\n",
       " 'won': 4,\n",
       " 'recollect': 1,\n",
       " 'old': 4,\n",
       " 'lady': 1,\n",
       " 'hand': 1,\n",
       " 'basket': 1,\n",
       " 'very': 1,\n",
       " 'reluctantly': 1,\n",
       " 'produced': 1,\n",
       " 'stipulated': 1,\n",
       " 'halfpence': 1,\n",
       " 'twopence': 1,\n",
       " 'halfpenny': 1,\n",
       " 'took': 3,\n",
       " 'immense': 1,\n",
       " 'great': 1,\n",
       " 'waste': 1,\n",
       " 'arithmetic': 1,\n",
       " 'endeavour': 1,\n",
       " 'without': 2,\n",
       " 'effect': 1,\n",
       " 'prove': 1,\n",
       " 'her': 8,\n",
       " 'fact': 2,\n",
       " 'long': 3,\n",
       " 'remembered': 1,\n",
       " 'remarkable': 1,\n",
       " 'she': 12,\n",
       " 'never': 4,\n",
       " 'drowned': 1,\n",
       " 'died': 2,\n",
       " 'triumphantly': 1,\n",
       " 'bed': 1,\n",
       " 'ninety': 1,\n",
       " 'understood': 1,\n",
       " 'last': 2,\n",
       " 'proudest': 1,\n",
       " 'boast': 1,\n",
       " 'water': 3,\n",
       " 'except': 1,\n",
       " 'upon': 1,\n",
       " 'bridge': 1,\n",
       " 'over': 3,\n",
       " 'tea': 2,\n",
       " 'extremely': 1,\n",
       " 'partial': 1,\n",
       " 'expressed': 1,\n",
       " 'indignation': 1,\n",
       " 'impiety': 1,\n",
       " 'mariners': 1,\n",
       " 'others': 1,\n",
       " 'presumption': 1,\n",
       " 'go': 6,\n",
       " 'meandering': 2,\n",
       " 'world': 4,\n",
       " 'vain': 1,\n",
       " 'represent': 1,\n",
       " 'conveniences': 1,\n",
       " 'perhaps': 2,\n",
       " 'included': 1,\n",
       " 'resulted': 1,\n",
       " 'objectionable': 1,\n",
       " 'practice': 1,\n",
       " 'always': 1,\n",
       " 'returned': 1,\n",
       " 'greater': 1,\n",
       " 'emphasis': 1,\n",
       " 'instinctive': 1,\n",
       " 'knowledge': 2,\n",
       " 'strength': 1,\n",
       " 'objection': 1,\n",
       " 'let': 5,\n",
       " 'us': 2,\n",
       " 'no': 11,\n",
       " 'where': 8,\n",
       " 'mind': 2,\n",
       " 'fear': 1,\n",
       " 'high': 1,\n",
       " 'free': 1,\n",
       " 'has': 7,\n",
       " 'broken': 1,\n",
       " 'fragments': 1,\n",
       " 'narrow': 1,\n",
       " 'domestic': 1,\n",
       " 'walls': 1,\n",
       " 'words': 2,\n",
       " 'depth': 1,\n",
       " 'truth': 1,\n",
       " 'tireless': 1,\n",
       " 'striving': 1,\n",
       " 'stretches': 1,\n",
       " 'its': 2,\n",
       " 'arms': 2,\n",
       " 'perfection': 1,\n",
       " 'clear': 1,\n",
       " 'stream': 1,\n",
       " 'reason': 1,\n",
       " 'lost': 1,\n",
       " 'dreary': 1,\n",
       " 'desert': 1,\n",
       " 'sand': 1,\n",
       " 'habit': 1,\n",
       " 'led': 1,\n",
       " 'forward': 1,\n",
       " 'thee': 1,\n",
       " 'ever': 5,\n",
       " 'widening': 1,\n",
       " 'thought': 3,\n",
       " 'action': 1,\n",
       " 'heaven': 1,\n",
       " 'freedom': 1,\n",
       " 'father': 3,\n",
       " 'awake': 1,\n",
       " 'those': 1,\n",
       " 'early': 1,\n",
       " 'amorphous': 1,\n",
       " 'when': 5,\n",
       " 'memory': 2,\n",
       " 'just': 3,\n",
       " 'begun': 1,\n",
       " 'full': 1,\n",
       " 'beginnings': 1,\n",
       " 'ends': 1,\n",
       " 'everything': 2,\n",
       " 'forever': 1,\n",
       " 'esthappen': 1,\n",
       " 'rahel': 4,\n",
       " 'themselves': 1,\n",
       " 'together': 1,\n",
       " 'separately': 2,\n",
       " 'individually': 1,\n",
       " 'we': 2,\n",
       " 'though': 3,\n",
       " 'rare': 1,\n",
       " 'breed': 1,\n",
       " 'siamese': 1,\n",
       " 'twins': 1,\n",
       " 'physically': 1,\n",
       " 'separate': 2,\n",
       " 'joint': 1,\n",
       " 'identities': 1,\n",
       " 'now': 4,\n",
       " 'later': 1,\n",
       " 'waking': 1,\n",
       " 'giggling': 1,\n",
       " 'estha': 6,\n",
       " 'funny': 1,\n",
       " 'dream': 1,\n",
       " 'other': 2,\n",
       " 'memories': 1,\n",
       " 'too': 2,\n",
       " 'right': 3,\n",
       " 'remembers': 2,\n",
       " 'instance': 1,\n",
       " 'hadn': 1,\n",
       " 'what': 4,\n",
       " 'orangedrink': 1,\n",
       " 'lemondrink': 1,\n",
       " 'man': 2,\n",
       " 'did': 1,\n",
       " 'abhilash': 1,\n",
       " 'talkies': 1,\n",
       " 'taste': 1,\n",
       " 'tomato': 1,\n",
       " 'sandwiches': 2,\n",
       " 'ate': 1,\n",
       " 'madras': 2,\n",
       " 'mail': 1,\n",
       " 'are': 6,\n",
       " 'things': 1,\n",
       " 'anyway': 1,\n",
       " 'thinks': 1,\n",
       " 'them': 3,\n",
       " 'longer': 1,\n",
       " 'd': 1,\n",
       " 'their': 3,\n",
       " 'lives': 1,\n",
       " 'size': 1,\n",
       " 'shape': 1,\n",
       " 'his': 7,\n",
       " 'hers': 1,\n",
       " 'edges': 1,\n",
       " 'borders': 1,\n",
       " 'boundaries': 1,\n",
       " 'brinks': 1,\n",
       " 'limits': 1,\n",
       " 'appeared': 1,\n",
       " 'like': 3,\n",
       " 'team': 1,\n",
       " 'trolls': 1,\n",
       " 'horizons': 1,\n",
       " 'creatures': 1,\n",
       " 'shadows': 1,\n",
       " 'patrolling': 1,\n",
       " 'blurry': 1,\n",
       " 'end': 2,\n",
       " 'gentle': 1,\n",
       " 'moons': 1,\n",
       " 'gathered': 1,\n",
       " 'under': 1,\n",
       " 'eyes': 1,\n",
       " 'ammu': 1,\n",
       " 'thirty': 1,\n",
       " 'look': 1,\n",
       " 'you': 14,\n",
       " 'shot': 5,\n",
       " 'opportunity': 4,\n",
       " 'seize': 1,\n",
       " 'wanted': 2,\n",
       " 'moment': 4,\n",
       " 'would': 1,\n",
       " 'capture': 2,\n",
       " 'slip': 1,\n",
       " 'yo': 4,\n",
       " 'palms': 1,\n",
       " 'sweaty': 1,\n",
       " 'knees': 1,\n",
       " 'weak': 1,\n",
       " 'heavy': 1,\n",
       " 'vomit': 1,\n",
       " 'sweater': 1,\n",
       " 'already': 1,\n",
       " 'mom': 2,\n",
       " 'spaghetti': 1,\n",
       " 'nervous': 1,\n",
       " 'surface': 1,\n",
       " 'looks': 1,\n",
       " 'calm': 1,\n",
       " 'ready': 1,\n",
       " 'drop': 1,\n",
       " 'bombs': 1,\n",
       " 'keeps': 1,\n",
       " 'forgetting': 1,\n",
       " 'wrote': 1,\n",
       " 'whole': 3,\n",
       " 'crowd': 1,\n",
       " 'goes': 7,\n",
       " 'so': 6,\n",
       " 'loud': 1,\n",
       " 'opens': 1,\n",
       " 'mouth': 1,\n",
       " 'choking': 1,\n",
       " 'how': 2,\n",
       " 'everybody': 1,\n",
       " 'joking': 1,\n",
       " 'run': 1,\n",
       " 'blaow': 1,\n",
       " 'snap': 1,\n",
       " 'back': 5,\n",
       " 'reality': 1,\n",
       " 'ope': 2,\n",
       " 'gravity': 1,\n",
       " 'rabbit': 1,\n",
       " 'choked': 1,\n",
       " 'mad': 1,\n",
       " 'give': 1,\n",
       " 'easy': 1,\n",
       " 'knows': 5,\n",
       " 'ropes': 1,\n",
       " 'matter': 1,\n",
       " 'dope': 1,\n",
       " 'broke': 1,\n",
       " 'stagnant': 1,\n",
       " 'mobile': 1,\n",
       " 'home': 3,\n",
       " 'lab': 1,\n",
       " 'again': 1,\n",
       " 'rhapsody': 1,\n",
       " 'hope': 1,\n",
       " 'pass': 1,\n",
       " 'him': 3,\n",
       " 'soul': 1,\n",
       " 'escaping': 1,\n",
       " 'hole': 1,\n",
       " 'gaping': 1,\n",
       " 'mine': 1,\n",
       " 'taking': 1,\n",
       " 'make': 1,\n",
       " 'king': 1,\n",
       " 'move': 1,\n",
       " 'toward': 1,\n",
       " 'new': 1,\n",
       " 'order': 1,\n",
       " 'normal': 1,\n",
       " 'boring': 1,\n",
       " 'superstardom': 1,\n",
       " 'close': 1,\n",
       " 'post': 1,\n",
       " 'mortem': 1,\n",
       " 'grows': 2,\n",
       " 'harder': 2,\n",
       " 'homie': 1,\n",
       " 'hotter': 1,\n",
       " 'blows': 1,\n",
       " 'hoes': 2,\n",
       " 'coast': 2,\n",
       " 'shows': 1,\n",
       " 'known': 1,\n",
       " 'globetrotter': 1,\n",
       " 'lonely': 1,\n",
       " 'roads': 3,\n",
       " 'god': 1,\n",
       " 'grown': 1,\n",
       " 'farther': 1,\n",
       " 'barely': 1,\n",
       " 'daughter': 1,\n",
       " 'hold': 1,\n",
       " 'your': 3,\n",
       " 'nose': 2,\n",
       " 'cause': 2,\n",
       " 'cold': 2,\n",
       " 'want': 1,\n",
       " 'mo': 1,\n",
       " 'product': 1,\n",
       " 'moved': 1,\n",
       " 'next': 2,\n",
       " 'schmoe': 1,\n",
       " 'flows': 1,\n",
       " 'dove': 1,\n",
       " 'sold': 1,\n",
       " 'nada': 1,\n",
       " 'soap': 1,\n",
       " 'opera': 1,\n",
       " 'told': 1,\n",
       " 'unfolds': 1,\n",
       " 'suppose': 1,\n",
       " 'partner': 1,\n",
       " 'beat': 1,\n",
       " 'da': 3,\n",
       " 'dom': 2,\n",
       " 'dah': 4,\n",
       " 'more': 1,\n",
       " 'games': 1,\n",
       " 'ma': 1,\n",
       " 'change': 1,\n",
       " 'call': 1,\n",
       " 'rage': 1,\n",
       " 'tear': 1,\n",
       " 'motherfuckin': 2,\n",
       " 'roof': 1,\n",
       " 'off': 2,\n",
       " 'dogs': 1,\n",
       " 'caged': 1,\n",
       " 'playin': 1,\n",
       " 'mood': 1,\n",
       " 'changed': 1,\n",
       " 've': 2,\n",
       " 'chewed': 1,\n",
       " 'spit': 1,\n",
       " 'booed': 1,\n",
       " 'stage': 1,\n",
       " 'rhymin': 1,\n",
       " 'stepped': 1,\n",
       " 'cypher': 1,\n",
       " 'best': 1,\n",
       " 'somebody': 1,\n",
       " 'payin': 1,\n",
       " 'pied': 1,\n",
       " 'piper': 1,\n",
       " 'pain': 1,\n",
       " 'inside': 1,\n",
       " 'amplified': 1,\n",
       " 'get': 3,\n",
       " 'nine': 1,\n",
       " 'provide': 1,\n",
       " 'type': 1,\n",
       " 'family': 1,\n",
       " 'goddamn': 1,\n",
       " 'food': 1,\n",
       " 'stamps': 1,\n",
       " 'buy': 1,\n",
       " 'diapers': 1,\n",
       " 'movie': 1,\n",
       " 'mekhi': 1,\n",
       " 'phifer': 1,\n",
       " 'times': 1,\n",
       " 'hard': 1,\n",
       " 'gettin': 1,\n",
       " 'even': 1,\n",
       " 'tryna': 1,\n",
       " 'feed': 1,\n",
       " 'seed': 1,\n",
       " 'plus': 1,\n",
       " 'teeter': 1,\n",
       " 'totter': 1,\n",
       " 'caught': 1,\n",
       " 'between': 1,\n",
       " 'bein': 1,\n",
       " 'prima': 1,\n",
       " 'donna': 1,\n",
       " 'mama': 1,\n",
       " 'drama': 1,\n",
       " 'screamin': 1,\n",
       " 'much': 1,\n",
       " 'wanna': 1,\n",
       " 'stay': 1,\n",
       " 'spot': 1,\n",
       " 'another': 2,\n",
       " 'monotony': 1,\n",
       " 'gotten': 1,\n",
       " 'point': 1,\n",
       " 'm': 1,\n",
       " 'snail': 1,\n",
       " 'got': 3,\n",
       " 'formulate': 1,\n",
       " 'plot': 1,\n",
       " 'jail': 1,\n",
       " 'success': 1,\n",
       " 'option': 1,\n",
       " 'failure': 1,\n",
       " 'love': 1,\n",
       " 'trailer': 1,\n",
       " 'cannot': 1,\n",
       " 'grow': 1,\n",
       " 'salem': 1,\n",
       " 'lot': 1,\n",
       " 'feet': 1,\n",
       " 'fail': 1,\n",
       " 'may': 1,\n",
       " 'lose': 2,\n",
       " 'yourself': 2,\n",
       " 'music': 2,\n",
       " 'miss': 2,\n",
       " 'chance': 2,\n",
       " 'blow': 2,\n",
       " 'comes': 2,\n",
       " 'once': 2,\n",
       " 'lifetime': 2,\n",
       " 'diverged': 2,\n",
       " 'yellow': 1,\n",
       " 'wood': 2,\n",
       " 'sorry': 1,\n",
       " 'could': 2,\n",
       " 'travel': 1,\n",
       " 'traveler': 1,\n",
       " 'stood': 1,\n",
       " 'looked': 1,\n",
       " 'far': 1,\n",
       " 'bent': 1,\n",
       " 'undergrowth': 1,\n",
       " 'fair': 1,\n",
       " 'claim': 1,\n",
       " 'grassy': 1,\n",
       " 'wear': 1,\n",
       " 'passing': 1,\n",
       " 'worn': 1,\n",
       " 'really': 1,\n",
       " 'same': 1,\n",
       " 'morning': 1,\n",
       " 'equally': 1,\n",
       " 'lay': 1,\n",
       " 'leaves': 1,\n",
       " 'step': 1,\n",
       " 'trodden': 1,\n",
       " 'black': 1,\n",
       " 'oh': 1,\n",
       " 'knowing': 1,\n",
       " 'leads': 1,\n",
       " 'doubted': 1,\n",
       " 'telling': 1,\n",
       " 'sigh': 1,\n",
       " 'somewhere': 1,\n",
       " 'ages': 2,\n",
       " 'hence': 1,\n",
       " 'less': 1,\n",
       " 'traveled': 1,\n",
       " 'made': 1,\n",
       " 'difference': 1}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1 - Creating a consolidated text variable which combines all these texts\n",
    "all_strings=[text[\"text_as_string\"]for text in all_texts]\n",
    "\n",
    "combined_text=all_strings[0]+all_strings[1]+all_strings[2]+all_strings[3]+all_strings[4]\n",
    "combined_text=combined_text.lower()\n",
    "\n",
    "#Splitting the text into words\n",
    "regex=re.compile(r\"\\b\\w+\\b\")\n",
    "all_words=re.findall(regex, combined_text)\n",
    "\n",
    "word_list=[]\n",
    "\n",
    "dictionary={}\n",
    "\n",
    "for word in all_words:\n",
    "    if word not in word_list:\n",
    "        word_list.append(word)\n",
    "        dictionary[word]=0\n",
    "    if word in word_list:\n",
    "        dictionary[word]=dictionary[word]+1\n",
    "dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
